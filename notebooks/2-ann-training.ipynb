{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Classification - Bank Customer Retention\n",
    "## Part 2 - ANN TRAINING\n",
    "In this notebook, we load the preprocessed training and testing dataset files and train ANN models.\n",
    "\n",
    "> **INPUT:** the preprocessed training and testing dataset files.<br>\n",
    "> **OUTPUT:** the trained ANN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "import tensorflow as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tensorflow version\n",
    "ts.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LOADING DATASET FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare file location and load dataset\n",
    "data_file_location = \"..\\\\data\\\\interim\\\\\"\n",
    "data_train_file_name = \"churn_modelling_preprocessed_train\"\n",
    "data_test_file_name = \"churn_modelling_preprocessed_test\"\n",
    "data_file_ext = \"csv\"\n",
    "\n",
    "data_train = pd.read_csv(data_file_location + data_train_file_name + \".\" + data_file_ext)\n",
    "data_test = pd.read_csv(data_file_location + data_test_file_name + \".\" + data_file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.569844</td>\n",
       "      <td>1.743090</td>\n",
       "      <td>0.169582</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>-0.464608</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>-1.215717</td>\n",
       "      <td>0.809503</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>1.106432</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.754865</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-2.304559</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>0.301026</td>\n",
       "      <td>-1.377440</td>\n",
       "      <td>-0.006312</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>-0.748664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.569844</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>-0.943129</td>\n",
       "      <td>-1.031415</td>\n",
       "      <td>0.579935</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>1.485335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.569844</td>\n",
       "      <td>1.743090</td>\n",
       "      <td>0.035566</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.473128</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>1.276528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.569844</td>\n",
       "      <td>1.743090</td>\n",
       "      <td>2.056114</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>1.736588</td>\n",
       "      <td>1.044737</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>0.809503</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>0.558378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geography_Germany  Geography_Spain  CreditScore    Gender       Age  \\\n",
       "0          -0.569844         1.743090     0.169582 -1.091687 -0.464608   \n",
       "1           1.754865        -0.573694    -2.304559  0.916013  0.301026   \n",
       "2          -0.569844        -0.573694    -1.191196 -1.091687 -0.943129   \n",
       "3          -0.569844         1.743090     0.035566  0.916013  0.109617   \n",
       "4          -0.569844         1.743090     2.056114 -1.091687  1.736588   \n",
       "\n",
       "     Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0  0.006661 -1.215717       0.809503   0.642595       -1.032270   \n",
       "1 -1.377440 -0.006312      -0.921591   0.642595        0.968738   \n",
       "2 -1.031415  0.579935      -0.921591   0.642595       -1.032270   \n",
       "3  0.006661  0.473128      -0.921591   0.642595       -1.032270   \n",
       "4  1.044737  0.810193       0.809503   0.642595        0.968738   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0         1.106432     0.0  \n",
       "1        -0.748664     0.0  \n",
       "2         1.485335     0.0  \n",
       "3         1.276528     0.0  \n",
       "4         0.558378     0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training dataset head\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.754865</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-0.552043</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>-0.368904</td>\n",
       "      <td>1.044737</td>\n",
       "      <td>0.879303</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>1.610857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.569844</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-1.314903</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>-1.031415</td>\n",
       "      <td>0.429722</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>0.495870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.569844</td>\n",
       "      <td>1.743090</td>\n",
       "      <td>0.571630</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>0.301026</td>\n",
       "      <td>1.044737</td>\n",
       "      <td>0.308583</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>-0.424787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.569844</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>1.416961</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>-0.656016</td>\n",
       "      <td>-0.339364</td>\n",
       "      <td>0.575336</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>-1.556190</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>-0.187777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.754865</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>0.571630</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>-0.081791</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>1.389611</td>\n",
       "      <td>0.809503</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geography_Germany  Geography_Spain  CreditScore    Gender       Age  \\\n",
       "0           1.754865        -0.573694    -0.552043 -1.091687 -0.368904   \n",
       "1          -0.569844        -0.573694    -1.314903 -1.091687  0.109617   \n",
       "2          -0.569844         1.743090     0.571630 -1.091687  0.301026   \n",
       "3          -0.569844        -0.573694     1.416961  0.916013 -0.656016   \n",
       "4           1.754865        -0.573694     0.571630  0.916013 -0.081791   \n",
       "\n",
       "     Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0  1.044737  0.879303      -0.921591   0.642595        0.968738   \n",
       "1 -1.031415  0.429722      -0.921591   0.642595       -1.032270   \n",
       "2  1.044737  0.308583      -0.921591   0.642595        0.968738   \n",
       "3 -0.339364  0.575336      -0.921591  -1.556190       -1.032270   \n",
       "4  0.006661  1.389611       0.809503   0.642595        0.968738   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0         1.610857     0.0  \n",
       "1         0.495870     1.0  \n",
       "2        -0.424787     0.0  \n",
       "3        -0.187777     0.0  \n",
       "4         0.616842     0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check testing dataset head\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset files into independent and dependent features\n",
    "X_train = data_train.iloc[:,0:-1]\n",
    "y_train = data_train.iloc[:,-1].values.reshape(-1,1)\n",
    "X_test = data_test.iloc[:,0:-1]\n",
    "y_test = data_test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BUILDING ANN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ANN\n",
    "ann = ts.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the input layer and the first hidden layer\n",
    "ann.add(ts.keras.layers.Dense(units=6, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "ann.add(ts.keras.layers.Dense(units=6, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer\n",
    "ann.add(ts.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TRAINING ANN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "ann.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\",\"recall\",\"precision\",\"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 735us/step - accuracy: 0.5319 - f1_score: 0.3493 - loss: 0.7295 - precision: 0.2584 - recall: 0.6110\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8057 - f1_score: 0.3253 - loss: 0.4621 - precision: 0.4864 - recall: 0.0048 \n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7935 - f1_score: 0.3480 - loss: 0.4592 - precision: 0.5689 - recall: 0.0861\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.8000 - f1_score: 0.3421 - loss: 0.4456 - precision: 0.5563 - recall: 0.1279 \n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.8126 - f1_score: 0.3442 - loss: 0.4327 - precision: 0.6668 - recall: 0.2000\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.8133 - f1_score: 0.3437 - loss: 0.4284 - precision: 0.6510 - recall: 0.2170\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.8215 - f1_score: 0.3388 - loss: 0.4164 - precision: 0.6771 - recall: 0.2403\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.8332 - f1_score: 0.3299 - loss: 0.4019 - precision: 0.7025 - recall: 0.2730\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.8343 - f1_score: 0.3357 - loss: 0.3981 - precision: 0.6938 - recall: 0.3200\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.8284 - f1_score: 0.3473 - loss: 0.4048 - precision: 0.7098 - recall: 0.3126\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.8286 - f1_score: 0.3427 - loss: 0.4087 - precision: 0.7044 - recall: 0.2944 \n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.8293 - f1_score: 0.3396 - loss: 0.3978 - precision: 0.6813 - recall: 0.3109\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.8300 - f1_score: 0.3384 - loss: 0.3907 - precision: 0.6909 - recall: 0.2988\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.8277 - f1_score: 0.3467 - loss: 0.4039 - precision: 0.7028 - recall: 0.3107\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.8319 - f1_score: 0.3467 - loss: 0.4016 - precision: 0.7016 - recall: 0.3451\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.8293 - f1_score: 0.3399 - loss: 0.3952 - precision: 0.6861 - recall: 0.3077\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.8326 - f1_score: 0.3507 - loss: 0.3970 - precision: 0.7087 - recall: 0.3607\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.8313 - f1_score: 0.3397 - loss: 0.3861 - precision: 0.6949 - recall: 0.3124\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8373 - f1_score: 0.3452 - loss: 0.3774 - precision: 0.7114 - recall: 0.3706\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8419 - f1_score: 0.3248 - loss: 0.3667 - precision: 0.7028 - recall: 0.3213\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8382 - f1_score: 0.3308 - loss: 0.3767 - precision: 0.7045 - recall: 0.3119 \n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8401 - f1_score: 0.3417 - loss: 0.3745 - precision: 0.7304 - recall: 0.3558\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.8333 - f1_score: 0.3313 - loss: 0.3694 - precision: 0.6833 - recall: 0.2971\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.8336 - f1_score: 0.3340 - loss: 0.3748 - precision: 0.6957 - recall: 0.3020\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.8358 - f1_score: 0.3453 - loss: 0.3733 - precision: 0.7183 - recall: 0.3502\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8348 - f1_score: 0.3310 - loss: 0.3678 - precision: 0.6901 - recall: 0.2991\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.8368 - f1_score: 0.3335 - loss: 0.3612 - precision: 0.7057 - recall: 0.3174\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.8391 - f1_score: 0.3327 - loss: 0.3597 - precision: 0.7043 - recall: 0.3344\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.8416 - f1_score: 0.3313 - loss: 0.3571 - precision: 0.7246 - recall: 0.3274\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.8306 - f1_score: 0.3467 - loss: 0.3799 - precision: 0.6944 - recall: 0.3408 \n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.8461 - f1_score: 0.3386 - loss: 0.3630 - precision: 0.7462 - recall: 0.3718\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.8407 - f1_score: 0.3486 - loss: 0.3661 - precision: 0.7333 - recall: 0.3858\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.8506 - f1_score: 0.3341 - loss: 0.3627 - precision: 0.7366 - recall: 0.3971\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8504 - f1_score: 0.3460 - loss: 0.3602 - precision: 0.7538 - recall: 0.4211\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.8458 - f1_score: 0.3438 - loss: 0.3639 - precision: 0.7425 - recall: 0.3935\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.8560 - f1_score: 0.3315 - loss: 0.3525 - precision: 0.7535 - recall: 0.4065\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8573 - f1_score: 0.3417 - loss: 0.3469 - precision: 0.7763 - recall: 0.4330\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.8530 - f1_score: 0.3465 - loss: 0.3585 - precision: 0.7633 - recall: 0.4328\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.8511 - f1_score: 0.3431 - loss: 0.3543 - precision: 0.7529 - recall: 0.4177\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.8591 - f1_score: 0.3378 - loss: 0.3519 - precision: 0.7640 - recall: 0.4444\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.8590 - f1_score: 0.3436 - loss: 0.3549 - precision: 0.7752 - recall: 0.4528\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.8585 - f1_score: 0.3475 - loss: 0.3514 - precision: 0.7813 - recall: 0.4547\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.8545 - f1_score: 0.3408 - loss: 0.3561 - precision: 0.7522 - recall: 0.4358\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.8599 - f1_score: 0.3387 - loss: 0.3504 - precision: 0.7636 - recall: 0.4538\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.8631 - f1_score: 0.3322 - loss: 0.3401 - precision: 0.7683 - recall: 0.4478\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8621 - f1_score: 0.3425 - loss: 0.3386 - precision: 0.7779 - recall: 0.4673\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8534 - f1_score: 0.3506 - loss: 0.3582 - precision: 0.7638 - recall: 0.4502\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.8579 - f1_score: 0.3358 - loss: 0.3509 - precision: 0.7585 - recall: 0.4349\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.8703 - f1_score: 0.3311 - loss: 0.3371 - precision: 0.7756 - recall: 0.4875\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.8625 - f1_score: 0.3416 - loss: 0.3441 - precision: 0.7679 - recall: 0.4759\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8635 - f1_score: 0.3383 - loss: 0.3512 - precision: 0.7837 - recall: 0.4572\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.8544 - f1_score: 0.3416 - loss: 0.3563 - precision: 0.7454 - recall: 0.4451\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.8628 - f1_score: 0.3385 - loss: 0.3507 - precision: 0.7627 - recall: 0.4753\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8665 - f1_score: 0.3332 - loss: 0.3346 - precision: 0.7695 - recall: 0.4760\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.8602 - f1_score: 0.3324 - loss: 0.3421 - precision: 0.7355 - recall: 0.4663\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8654 - f1_score: 0.3339 - loss: 0.3386 - precision: 0.7586 - recall: 0.4838\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.8623 - f1_score: 0.3466 - loss: 0.3462 - precision: 0.7674 - recall: 0.4927\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.8616 - f1_score: 0.3463 - loss: 0.3423 - precision: 0.7713 - recall: 0.4818\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.8637 - f1_score: 0.3452 - loss: 0.3436 - precision: 0.7776 - recall: 0.4870\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8641 - f1_score: 0.3324 - loss: 0.3343 - precision: 0.7616 - recall: 0.4655\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8604 - f1_score: 0.3406 - loss: 0.3433 - precision: 0.7647 - recall: 0.4609\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8722 - f1_score: 0.3259 - loss: 0.3281 - precision: 0.7650 - recall: 0.4958\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.8648 - f1_score: 0.3418 - loss: 0.3413 - precision: 0.7588 - recall: 0.5063\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.8676 - f1_score: 0.3218 - loss: 0.3370 - precision: 0.7658 - recall: 0.4454\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.8644 - f1_score: 0.3417 - loss: 0.3402 - precision: 0.7639 - recall: 0.4949\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.8590 - f1_score: 0.3361 - loss: 0.3439 - precision: 0.7236 - recall: 0.4916\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.8641 - f1_score: 0.3329 - loss: 0.3456 - precision: 0.7567 - recall: 0.4699\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.8636 - f1_score: 0.3391 - loss: 0.3401 - precision: 0.7604 - recall: 0.4864\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.8681 - f1_score: 0.3296 - loss: 0.3313 - precision: 0.7662 - recall: 0.4787\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8629 - f1_score: 0.3419 - loss: 0.3368 - precision: 0.7510 - recall: 0.5012\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.8685 - f1_score: 0.3442 - loss: 0.3364 - precision: 0.7955 - recall: 0.4970\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8631 - f1_score: 0.3353 - loss: 0.3437 - precision: 0.7549 - recall: 0.4752\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8701 - f1_score: 0.3316 - loss: 0.3270 - precision: 0.7705 - recall: 0.4958\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.8652 - f1_score: 0.3460 - loss: 0.3324 - precision: 0.7708 - recall: 0.5053\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.8631 - f1_score: 0.3347 - loss: 0.3442 - precision: 0.7658 - recall: 0.4605\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.8674 - f1_score: 0.3241 - loss: 0.3339 - precision: 0.7591 - recall: 0.4639\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.8660 - f1_score: 0.3327 - loss: 0.3367 - precision: 0.7562 - recall: 0.4863\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - accuracy: 0.8641 - f1_score: 0.3412 - loss: 0.3329 - precision: 0.7411 - recall: 0.5228\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.8643 - f1_score: 0.3388 - loss: 0.3323 - precision: 0.7567 - recall: 0.4919\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.8670 - f1_score: 0.3394 - loss: 0.3318 - precision: 0.7672 - recall: 0.5018\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.8635 - f1_score: 0.3433 - loss: 0.3373 - precision: 0.7739 - recall: 0.4820\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.8650 - f1_score: 0.3373 - loss: 0.3346 - precision: 0.7582 - recall: 0.4910\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.8615 - f1_score: 0.3341 - loss: 0.3389 - precision: 0.7374 - recall: 0.4818\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.8604 - f1_score: 0.3428 - loss: 0.3434 - precision: 0.7542 - recall: 0.4816\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.8620 - f1_score: 0.3385 - loss: 0.3419 - precision: 0.7495 - recall: 0.4833\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8625 - f1_score: 0.3386 - loss: 0.3406 - precision: 0.7495 - recall: 0.4854 \n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8623 - f1_score: 0.3426 - loss: 0.3362 - precision: 0.7538 - recall: 0.4963\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.8627 - f1_score: 0.3383 - loss: 0.3360 - precision: 0.7604 - recall: 0.4753\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.8608 - f1_score: 0.3291 - loss: 0.3392 - precision: 0.7338 - recall: 0.4606\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.8631 - f1_score: 0.3417 - loss: 0.3357 - precision: 0.7616 - recall: 0.4857\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.8698 - f1_score: 0.3395 - loss: 0.3331 - precision: 0.7824 - recall: 0.5014\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8632 - f1_score: 0.3434 - loss: 0.3364 - precision: 0.7588 - recall: 0.4992\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8646 - f1_score: 0.3473 - loss: 0.3397 - precision: 0.7889 - recall: 0.4854\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8568 - f1_score: 0.3533 - loss: 0.3497 - precision: 0.7639 - recall: 0.4818\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.8644 - f1_score: 0.3355 - loss: 0.3335 - precision: 0.7597 - recall: 0.4787\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.8629 - f1_score: 0.3387 - loss: 0.3375 - precision: 0.7672 - recall: 0.4713\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8654 - f1_score: 0.3359 - loss: 0.3324 - precision: 0.7520 - recall: 0.4974\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.8666 - f1_score: 0.3339 - loss: 0.3315 - precision: 0.7510 - recall: 0.5006\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8676 - f1_score: 0.3367 - loss: 0.3337 - precision: 0.7864 - recall: 0.4764\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.8675 - f1_score: 0.3301 - loss: 0.3289 - precision: 0.7604 - recall: 0.4822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2527bd86ed0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "ann.fit(X_train, y_train, batch_size=32, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
